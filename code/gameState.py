# -*- coding: utf-8 -*-
import random
import numpy as np
import math
from scipy.stats import norm

class GameState:
    """
    Class to hold game state for each eval/game.
    """

    # Game states
    UNBLOCKED = 0
    BLOCKED = 1
    ATTACKER_DETECTED = 2


    def __init__(self, experiment):
        """
        Set up the game state given initialization parameters as listed.
        """
        self.defender_strategy = experiment.defender_strategy

        self.time_limit = experiment.game_time_limit

        # Which CA clasifiers are we using? (currently none)
        self.ca_classifiers = experiment.ca_classifiers

        # game invariants and measurements:
        self.t = 0
        self.state = GameState.UNBLOCKED
        # How long has the game been blocked in total?
        self.time_blocked = 0
        # amount of traffic generated by the user each turn
        self.user_history = []
        # A_u = total traffic generated by the user (sum of user_history)
        self.A_u = 0
        # user behavior values (only relevant when traffic is generated)
        self.behavior_history = []
        # behavior_mask is 1 for turn t if A(t) > 0, and 0 otherwise
        self.behavior_mask = []
        # the defender is interested in maximizing either A_u or the total
        # number of successful user interactions, so track the latter in case
        self.sum_of_behavior_mask = 0
        # listening mask is 1 if the attacker is listening at turn t
        self.listening_mask = []
        # Amount of user traffic observed by the attacker
        # omega = L(t) = \sum_i A(t_i) * (l(t_i) == 1)
        self.omega = 0
        # Amount of successful attacks by the attacker
        self.attacker_reward = 0

        # game parameters:
        self.lambda_u = experiment.lambda_u
        self.beta_u = experiment.beta_u
        self.sigma_u = experiment.sigma_u
        self.eta_u = experiment.eta_u
        self.nu_r = experiment.nu_r
        self.delta_l = experiment.delta_l
        self.delta_a = experiment.delta_a
        self.q = experiment.q
        self.gamma = experiment.gamma
        self.rho = experiment.rho
        # we're out of Greek, someone as the frats for more
        self.user_bonus = experiment.user_bonus
        self.attacker_penalty = experiment.attacker_penalty

        # Do we have the IDS serve as the end-game or the defender?
        self.IDLess = experiment.IDLess
        
        #self.m = 0
        #self.C_a = 0

        # Cut-off point for detecting attack: if beta_u > c then positive
        # (assuming being attacked); false positives possible
        # the cut off is the point at which the area under the normal curve to
        # the right of the cut off is equal to the false positive rate
        self.c_r = norm.ppf(1 - self.eta_u)


    def T(self):
        """
        Return current time step in simulation
        """
        return self.t


    def B(self):
        """
        Return state (blocked or unblocked)
        """
        return self.state


    def AO(self):
        """
        Return amount of observation by the attacker
        """
        return self.omega


    def AR(self):
        """
        Return current amount of attacker reward
        """
        return self.attacker_reward

    def BH(self):
        """
        Return the last observed behavior value from 
        user or attacker
        """
        return self.behavior_history[-1]

    def BM(self):
        """
        Return true if the user or attacker actually generated behavior. If this
        is false, the value returned by BH() is meaningless. But I don't know
        how to "force" BH() to return a value only conditional upon this being
        true in an evolved algorithm, other than the let the EA figure it out
        itself, so *shrug*
        """
        return self.behavior_mask[-1]

    def play_turn(self, world_data, attacker_controllers, defender_controllers):
        """
        Play a turn of a game given world_data to log world updates
        and controllers for Attacker and Defenders.

        During a turn, the following takes place (somewhat sequentially):

        The attacker decides whether to wait, listen, or attack given the
        current game state and the amount of prior traffic seen

        If the game state is non-blocking:
        The user generates 0 or more traffic according to a poisson distribution
        with mean lambda.

        TODO: find out whether the following is consistent with the paper. We
        will probably end up modifying it a bit anyways.

        If the game state is non-blocking:
        If the attacker generates traffic:
        The defender decides whether to block based on traffic generated by the
        attacker
        If the attacker does not generate traffic and the user generates
        traffic:
        The defender decides whether to block based on traffic generated by the
        user

        :ODOT

        IDS checks are performed based on the attacker's actions and the game
        state may transition to attacker detected and game_over

        The game state may transition to blocked depending on the actions of the
        defender

        The game state may transition to unblocked depending on if the game was
        blocked during the current turn
        """
        # If we're here we know the game isn't over, but that could change.
        game_over = False

        # Increment time step. Type in unnecessary comments.
        self.t += 1

        if (self.state == GameState.BLOCKED): self.time_blocked += 1

        # Assume one attacker and one defender for now
        # NOTE multi-user / attacker situations might be easy to extend
        attacker = attacker_controllers[0]
        defender = defender_controllers[0]

        # First let the attacker decide their move

        # Attacker
        attacker.decide_move(self)

        # Then see how the current turn plays out

        # The attacker starts first
        self.listening_mask.append(attacker.next_move == 'listen')

        # Then the user generates traffic if the game state allows
        if (self.state == GameState.UNBLOCKED):
            self.user_history.append(np.random.poisson(self.lambda_u))
            self.A_u += self.user_history[-1]
        else:
            self.user_history.append(0)

        # If the attacker decides to attack, the traffic generated by the
        # attacker currently subsumes any traffic generated by the user in the
        # defender's decision (see TODO in docstring above)
        if (attacker.next_move == 'attack' and
            self.state == GameState.UNBLOCKED):
            # Use basic model with no CA classifiers
            if (len(self.ca_classifiers) == 0):
                self.behavior_history.append(np.random.normal(
                    self.beta_u * (1 + math.exp(-self.gamma * self.omega)),
                    self.sigma_u * (1 + math.exp(-self.gamma * self.omega))))
                self.behavior_mask.append(True)
        elif (self.user_history[-1]):
            # if the user generates any traffic, that behavior is N(beta_u, sigma_u)
            self.behavior_history.append(np.random.normal(self.beta_u,
                                                          self.sigma_u))
            self.behavior_mask.append(True)
        else:
            self.behavior_history.append(0)
            self.behavior_mask.append(False)

        # Defender
        if (self.defender_strategy == 'ccegp'):
            defender.decide_move(self)
        else: # using defender with static false positive rate:
            # First check if the game is currently blocked, then there's nothing
            # for the defender to do.
            if (self.state == GameState.BLOCKED):
                defender.next_move = 'block'
            else:
                # (if behavior > false positive cut-off)
                if ((len(self.behavior_mask) > 0) # First turn = unblock
                    and (self.behavior_mask[-1])
                    and (self.behavior_history[-1] > self.c_r)):
                    defender.next_move = 'block'
                else:
                    defender.next_move = 'unblock'

        # transition to blocked if the defender decides to block
        if (self.state == GameState.UNBLOCKED and defender.next_move == 'block'):
            self.state = GameState.BLOCKED
        elif (self.state == GameState.BLOCKED):
            # remain blocked with probability q
            self.state = (GameState.UNBLOCKED, GameState.BLOCKED)[np.random.uniform(0,1) < self.q]
        # else remain unblocked

        if (attacker.next_move == 'listen'):
            if (random.random() < self.delta_l):
                self.state = GameState.ATTACKER_DETECTED
            else:
                self.omega += self.user_history[-1] #TODO: index by t for less confusion
        elif (attacker.next_move == 'attack'):
            if ((not self.IDLess) and (random.random() < self.delta_a)):
                self.state = GameState.ATTACKER_DETECTED
            elif ((self.IDLess) and (defender.next_move == 'block')):
                self.state = GameState.ATTACKER_DETECTED
            else:
                # the attacker reward is discounted by a rho factor in to add time pressure
                self.attacker_reward += self.rho ** (self.t - 1)

        # If attacker is detected, game over
        if ((self.state == GameState.ATTACKER_DETECTED)
            or ((self.time_limit - self.t) == 0)):
            game_over = True

        # Logging
        world_data.append('attacker: ' + attacker.next_move + ' vs. defender: '
                          + defender.next_move + '\n')

        return game_over


    def calculate_attacker_fitness(self):
        """
        Calculate and return fitness for the attacker based on game state
        """
        return self.attacker_reward


    def calculate_defender_fitness(self):
        """
        Calculate and return fitness for the defender based on game state
        """
        # Here we make the tradeoff between service and security.
        # If only judged by amount of information lost, the defender
        # will ALWAYS block, which provides terrible service.
        return (self.user_bonus * (self.A_u)\
            - self.attacker_penalty * (self.attacker_reward)) / self.t


"""

Saritas:

User behvaior:
t = time slot
u = user
r = resource
Lambda_u(t) = amount of traffic generated by user u in time slot t
(Poisson distributed with parameter lambda_u)
--> arrivals modeled by Poisson process with intensity lambda_u/iota where
iota = length of time slot)

m = per-time-slot cost of operating IDS
user behavior described by Gaussian distribution Beta_u ~ Nu(beta_u, sigma_u)
  with mean beta_u and variance sigma_u

user behavior is verified at end of every time slot; decision is made based
  on match of user behavior model and actual behavior during slot.

c = cut-off point
if Beta_user > c then positive (assuming being attacked); false positives possible
eta_u = false positive (FP) rate
system applies detection threshold of c = Phi_u^-1 (1 - eta_u) where
  Phi_u is cumulative dsitribution function (CDF) of Beta_u

S = system, which is in one of three states: BL, UB, or AD (blocked, unblocked, attacker detected)
In state UB, user can generate reward nu_r
If user fails CA (either FP or true positive (TP)), system changes from UB to BL

q = probability that user blocked in time state t is unblocked in t+1

L(t) = number of observations by attacker at time t

At time t:
    l(t) = 1, a(t) = 0 if listening



"""
